# 단순 선형 회귀의 사본

# 1. 기본 개념

$y =Wx +b$이 수식이 단순 선형 회귀의 수식이다. 중학교때 배운 익숙한 1차 함수가 보이는가? 가중치를 뜻하는 $W$와 편향을 뜻하는 $b$가 바로 컴퓨터가 학습하는 파라미터다. 

아래와 같은 학생의 공부시간에 따른 점수 데이터가 있다고 가정할 때,

[점수 데이터](%E1%84%83%E1%85%A1%E1%86%AB%E1%84%89%E1%85%AE%E1%86%AB%20%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%E1%84%8B%E1%85%B4%20%E1%84%89%E1%85%A1%E1%84%87%E1%85%A9%E1%86%AB%20fba31c361b4046c5a4676698d6c86c3d/%E1%84%8C%E1%85%A5%E1%86%B7%E1%84%89%E1%85%AE%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20688fd1d5817c40f99fe2854649392688.csv)

$x$에 공부시간을, $y$에 점수를 대입하여 계산하면 아래와 같은 수식이 나온다.

$25 = W*2 + b$

$30 = W*3 + b$

$35 = W*4 + b$

$40 = W*5 + b$

이렇게되면 MSE와 같은 손실함수와 SGD와 같은 Optimizer함수를 사용하여 학습하며 최적의 $W$를 찾는데, 학습이 완료되면, $x$입력 값으로 6을 넣었을 때 45를 출력한다. 

# 2. 사전 지식

아래와 같은 사전지식이 있어야 원할하게 해당 개념을 이해할 수 있음을 알려드립니다.

[기본 인공지능 용어](%E1%84%83%E1%85%A1%E1%86%AB%E1%84%89%E1%85%AE%E1%86%AB%20%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%E1%84%8B%E1%85%B4%20%E1%84%89%E1%85%A1%E1%84%87%E1%85%A9%E1%86%AB%20fba31c361b4046c5a4676698d6c86c3d/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A9%E1%86%BC%E1%84%8C%E1%85%B5%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%8B%E1%85%A5%2031e61ec7b57141788b4faafcd4244be5.md)

# 3. 자세한 학습

---

# 출처

---

- 딥러닝을 이용한 자연어 처리 입문 - [https://wikidocs.net/21670](https://wikidocs.net/21670)